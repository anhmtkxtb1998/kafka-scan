import os
import sys
import json
import time
import nmap
import ipaddress
import threading
from datetime import datetime
from threading import Thread, Lock
from concurrent.futures import ThreadPoolExecutor
from kafka import KafkaConsumer, KafkaProducer
# ===================== Redis (realtime config) =====================
import redis
try:
    from scan_ip.redis_utils import make_redis_clients
    from scan_ip.config import CONFIG_CHANNEL, BOT_KIND, DEFAULT_SCAN_ARGS
    from scan_ip.config import KAFKA_BOOTSTRAP_SERVERS, TOPIC_SCAN, TOPIC_SCAN_RESULT, TOPIC_WRITE_IP_RANGE
except Exception:
    # fallback if executing from the folder directly
    from redis_utils import make_redis_clients
    from config import CONFIG_CHANNEL, BOT_KIND, DEFAULT_SCAN_ARGS
    from config import KAFKA_BOOTSTRAP_SERVERS, TOPIC_SCAN, TOPIC_SCAN_RESULT, TOPIC_WRITE_IP_RANGE

_rds_cmd, _rds_pub = make_redis_clients(BOT_KIND)

CONFIG = {'args': DEFAULT_SCAN_ARGS}
CONFIG_LOCK = Lock()

def _set_args(new_args: str):
    if not new_args:
        return
    with CONFIG_LOCK:
        if CONFIG.get('args') != new_args:
            print(f"üîÑ C·∫≠p nh·∫≠t args ‚Üí {new_args}")
        CONFIG['args'] = new_args

def load_current_args() -> bool:
    """ƒê·ªçc key cfg:<BOT_KIND>:current t·ª´ Redis ƒë·ªÉ n·∫°p args hi·ªán h√†nh."""
    if not _rds_cmd:
        return False
    key = f"cfg:{BOT_KIND}:current"
    try:
        doc = _rds_cmd.get(key)
        if not doc:
            print(f"‚ÑπÔ∏è Redis ch∆∞a c√≥ {key}. D√πng DEFAULT_SCAN_ARGS.")
            return False
        data = json.loads(doc)
        args = data.get('args')
        if args:
            _set_args(args)
            return True
        print(f"‚ÑπÔ∏è Key {key} kh√¥ng c√≥ 'args'.")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói load_current_args(): {e}")
    return False

def pubsub_listener(stop_event: threading.Event | None = None):
    """
    L·∫Øng nghe CONFIG_CHANNEL b·ªÅn b·ªâ:
    - D√πng get_message(timeout=30) ƒë·ªÉ tr√°nh socket timeout.
    - G·ª≠i ping keepalive ƒë·ªãnh k·ª≥, auto-reconnect khi l·ªói.
    """
    if not _rds_pub:
        return
    while True:
        try:
            p = _rds_pub.pubsub()
            p.subscribe(CONFIG_CHANNEL)
            print(f"üì° Subscribed Redis Pub/Sub channel: {CONFIG_CHANNEL}")
            last_ping = time.time()
            while True:
                if stop_event and stop_event.is_set():
                    p.close()
                    return
                msg = p.get_message(ignore_subscribe_messages=True, timeout=30.0)
                if msg is None:
                    # keepalive ping qua client command
                    if _rds_cmd and (time.time() - last_ping >= 25):
                        try:
                            _rds_cmd.ping()
                        except Exception as e:
                            raise e
                        last_ping = time.time()
                    continue

                data = msg.get('data')
                try:
                    evt = json.loads(data) if isinstance(data, str) else json.loads(data or "{}")
                except Exception:
                    evt = {}
                # l·ªçc theo bot_kind n·∫øu c√≥
                if evt.get('bot_kind') and evt['bot_kind'] != BOT_KIND:
                    continue
                load_current_args()

        except (redis.exceptions.ConnectionError, redis.exceptions.TimeoutError) as e:
            print(f"‚ö†Ô∏è Pub/Sub b·ªã ng·∫Øt ({e}). Th·ª≠ k·∫øt n·ªëi l·∫°i sau 2s...")
            time.sleep(2)
            continue
        except Exception as e:
            print(f"‚ö†Ô∏è Pub/Sub error: {e}. Reconnect sau 2s...")
            time.sleep(2)
            continue

def get_scan_args() -> str:
    """L·∫•y args m·ªõi nh·∫•t (realtime) cho m·ªói IP."""
    with CONFIG_LOCK:
        return CONFIG['args'] or DEFAULT_SCAN_ARGS

# ===================== Kafka =====================
KAFKA_BOOTSTRAP_SERVERS = os.getenv('KAFKA_BOOTSTRAP_SERVERS', '192.168.89.138:9092')
TOPIC_SCAN = os.getenv('TOPIC_SCAN', 'scan-topic')
TOPIC_SCAN_RESULT = os.getenv('TOPIC_SCAN_RESULT', 'scan-results')
TOPIC_WRITE_IP_RANGE = os.getenv('TOPIC_WRITE_IP_RANGE', 'write_ip_ranges')

def create_kafka_consumer():
    return KafkaConsumer(
        TOPIC_SCAN,
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        group_id='scan_group',
        value_deserializer=lambda m: json.loads(m.decode('utf-8')),
        auto_offset_reset='earliest',
        enable_auto_commit=True
    )

def create_kafka_producer():
    return KafkaProducer(
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )

# ===================== Qu√©t m·∫°ng =====================
def expand_cidr_to_ips(cidr_range):
    try:
        network = ipaddress.IPv4Network(cidr_range, strict=False)
        return [str(ip) for ip in network.hosts()]
    except Exception as e:
        print(f"‚ö†Ô∏è CIDR kh√¥ng h·ª£p l·ªá ({cidr_range}): {e}")
        return []

def scan_single_ip(scanner, ip, ip_range_id, scan_args):
    results = []
    print(f'üîé Scan {ip} v·ªõi args: {scan_args}')
    try:
        scanner.scan(hosts=ip, arguments=scan_args)
        if ip in scanner.all_hosts():
            host = scanner[ip]
            status = (host.get('status') or {}).get('state')
            tcp = host.get('tcp')
            if tcp:
                for port, port_data in tcp.items():
                    if port_data.get('state') == 'open':
                        results.append({
                            'ip_range_id': ip_range_id,
                            'ip': ip,
                            'port': port,
                            'status_port': 'open',
                            'first_detect': str(datetime.now()),
                            'last_scan': str(datetime.now()),
                            'os': {},
                            'detail_port': {}
                        })
            elif status == 'up':
                # liveness mode (vd: -sn)
                results.append({
                    'ip_range_id': ip_range_id,
                    'ip': ip,
                    'port': None,
                    'status_port': 'alive',
                    'first_detect': str(datetime.now()),
                    'last_scan': str(datetime.now()),
                    'os': {},
                    'detail_port': {}
                })
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi qu√©t {ip} v·ªõi args='{scan_args}': {e}")
    return results

def scan_ip_group(ip_range_id, parent_name, unit_name, ips, producer=None):
    print(f"üîç ƒêang qu√©t {len(ips)} IP (args s·∫Ω l·∫•y realtime t·ª´ng IP)")
    results = []

    # Chia 2 chunk ƒë∆°n gi·∫£n ƒë·ªÉ song song nh·∫π
    if len(ips) <= 1:
        chunks = [ips]
    else:
        mid = len(ips) // 2
        chunks = [ips[:mid], ips[mid:]]

    def worker(ip_chunk):
        local_results = []
        scanner = nmap.PortScanner()
        last_args_shown = None
        for ip in ip_chunk:
            current_args = get_scan_args()  # üîÑ realtime tr∆∞·ªõc M·ªñI IP
            if current_args != last_args_shown:
                print(f"üß≠ Args hi·ªán h√†nh: {current_args}")
                last_args_shown = current_args
            local_results += scan_single_ip(scanner, ip, ip_range_id, current_args)
        return local_results

    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [executor.submit(worker, chunk) for chunk in chunks if chunk]
        for f in futures:
            results.extend(f.result())

    # ‚úÖ Th√¥ng b√°o ƒë√£ qu√©t xong d·∫£i
    if producer:
        update_msg = {"ip_range_id": ip_range_id, "last_scanned_at": datetime.utcnow().isoformat()}
        producer.send(TOPIC_WRITE_IP_RANGE, update_msg)
        producer.flush()
        print(f"üìå ƒê√£ g·ª≠i th√¥ng b√°o qu√©t xong d·∫£i IP ID={ip_range_id} l√™n topic {TOPIC_WRITE_IP_RANGE}.")

    return results

# ===================== Task Handler =====================
def handle_task(task, producer, index):
    try:
        ip_range_id = task['ip_range_id']
        parent_name = task.get('parent_unit_name')
        unit_name = task.get('unit_name')
        cidr = task['cidr']

        print(f"\nüöÄ [Consumer #{index}] Task: {parent_name} / {unit_name} | CIDR: {cidr}")
        ips = expand_cidr_to_ips(cidr)
        if not ips:
            print(f"‚ö†Ô∏è CIDR {cidr} kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng c√≥ IP.")
            return

        results = scan_ip_group(ip_range_id, parent_name, unit_name, ips, producer)

        if results:
            print(f"üì§ [Consumer #{index}] G·ª≠i {len(results)} k·∫øt qu·∫£...")
            for entry in results:
                producer.send(TOPIC_SCAN_RESULT, entry)
            producer.flush()
            print(f"‚úÖ [Consumer #{index}] ƒê√£ g·ª≠i to√†n b·ªô k·∫øt qu·∫£.")
        else:
            print(f"‚ö†Ô∏è [Consumer #{index}] Kh√¥ng t√¨m th·∫•y port m·ªü ho·∫∑c host alive.")

    except Exception as e:
        print(f"‚ùó [Consumer #{index}] L·ªói x·ª≠ l√Ω task: {e}")

# ===================== Consumer worker =====================
def consumer_worker(index):
    consumer = create_kafka_consumer()
    producer = create_kafka_producer()
    print(f"üì° Consumer #{index} kh·ªüi ƒë·ªông v√† ƒëang l·∫Øng nghe...")

    try:
        for message in consumer:
            task = message.value
            handle_task(task, producer, index)
    except KeyboardInterrupt:
        print(f"\nüõë Consumer #{index} d·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
    finally:
        consumer.close()

# ===================== Main =====================
if __name__ == "__main__":
    # N·∫°p args l·∫ßn ƒë·∫ßu t·ª´ Redis (n·∫øu c√≥)
    load_current_args()

    # B·∫≠t Pub/Sub ƒë·ªÉ realtime ƒë·ªïi tham s·ªë
    stop_evt = None
    if _rds_pub:
        stop_evt = threading.Event()
        t_cfg = threading.Thread(target=pubsub_listener, args=(stop_evt,), daemon=True)
        t_cfg.start()

    print("üöÄ Kh·ªüi ƒë·ªông 2 consumer song song...")
    threads = []
    for i in range(2):
        t = Thread(target=consumer_worker, args=(i+1,), daemon=True)
        t.start()
        threads.append(t)

    try:
        for t in threads:
            t.join()
    except KeyboardInterrupt:
        print("\nüõë T·∫Øt to√†n b·ªô consumer do KeyboardInterrupt.")
        if stop_evt:
            stop_evt.set()
        sys.exit(0)
